## Overview
This repository contains files and code related to the analysis and modeling of a bank dataset using decision tree and naive Bayes algorithms. The dataset, `bank_full.xlsx`, is included along with its sample version `bank_data.xlsx`. Various models and their corresponding optimized versions are provided, along with pre-processing files for Jupyter notebook.

### Instructions

1. `FinalDTModels.mat`: Contains the final optimized model code for the decision tree
2. `FinalNBModel.mat`: Contains the final optimized model code for naive Bayes
3. `bank_full.xlsx`: Full dataset of the bank
4. `bank_data.xlsx`: Sample of the full dataset
5. `DecisionTreeWorkSpace.mat`: Workspace for decision tree containing the final model
6. `NaiveBayesWorkSpace.mat`: Workspace for naive Bayes containing the final model
7. `OptimizedDecisionTree.mat`: Contains the optimized decision tree model
8. `OptimizedNaiveBayes.mat`: Contains the optimized naive Bayes model
9. `Decision Tree Graphics`: Folder containing graphics related to the decision tree
10. `Naive Bayes Graphics`: Folder containing graphics related to naive Bayes
11. `Pre-Processing Data.ipynb`: Files for pre-processing in Jupyter notebook

### Contents

- `DecisionTreeSupplementaryFinal.m`: Supplementary file for decision tree modeling
- `NaiveBayesSupplementaryFinal.m`: Supplementary file for naive Bayes modeling
- `FinalDTModels.m`: Decision tree model code
- `FinalNBModel.m`: Naive Bayes model code
- `optimizedNaiveBayes.m`: Optimized naive Bayes model code

### Explanation
- The `Supplementary.pdf` provides detailed explanations, insights, and methodologies used in the analysis and modeling process

- This study compares Multi-Layer Perceptrons (MLP) and Support Vector Machines (SVM) for recognizing handwritten digits using the MNIST dataset. Models are optimized via random search and evaluated using performance metrics like Accuracy, Precision, Recall, ROC, and Confusion Matrices. SVM emerges as the preferred model due to its superior performance and efficiency.

- Models are trained on pre-processed data using PyTorch for MLP and scikit-learn for SVM. Hyperparameters are optimized using random search, and models are evaluated using cross-validation.

